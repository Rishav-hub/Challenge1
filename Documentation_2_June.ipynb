{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Documentation 2- June",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Kj5rV4_7fGUPeZ_kNfgvHT0zCDxH7O4n",
      "authorship_tag": "ABX9TyM1zJqDfa6SgPdS7wv/S0iD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishav-hub/Challenge1/blob/main/Documentation_2_June.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyr-WmEJa7s9"
      },
      "source": [
        "### What do you mean by training of Neural Network ?\n",
        "It is a mechanism of providing the network with the desired output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU2e8NHVbbvi"
      },
      "source": [
        "### What do you mean by DNN ?\n",
        "DNNs or Deep Neural networks are archietecture that are made of many layers. All the layers are connected. They are specifically used to perform some complex task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC21h2U6cg1U"
      },
      "source": [
        "### What is a Sequential model ?\n",
        "A plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "\n",
        "```\n",
        "model = keras.models.Sequential()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mEyur3WdqO3"
      },
      "source": [
        "### Why are callbacks implemented while fitting the model ?\n",
        "Keras will call during training at the start and end of training, at the start and end of each epoch and even before and after processing each batch. \n",
        "\n",
        "Some functionalities are:\n",
        "- Saving checkpoints\n",
        "- Early Stopping\n",
        "- log directory for tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llucnk5Pdf9Q"
      },
      "source": [
        "### Why do we flatten the input of a image ?\n",
        "The input of an image for example in MNIST dataset has (28, 28) shape but the input layer accept that in a single dimension. So Flatten converts the (28,28) to (None, 784). Now the input layer has 784 neurons. \n",
        "\n",
        "\n",
        "```\n",
        "tf.keras.layers.Flatten(input_shape=[28, 28])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omR0tZIqgoeu"
      },
      "source": [
        "### How are parameters of the layers calculated ?\n",
        "If its just made out of dense layers then it's \n",
        "\n",
        "$firsLayer \\times secondLayer + bias$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PneDRT0ohJ8I"
      },
      "source": [
        "### What do one epoch means ?\n",
        "One epoch is one forward **propagation + back propagation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e18BaIEnwGXw"
      },
      "source": [
        "### What are the problems faced while trainign a NN ?\n",
        "- Vanishing and exploding Gradients\n",
        "- It requires lot of data to train (Transfer learning or data augmentation)\n",
        "- Increase in size of NN (better optimizers)\n",
        "- Risk of overfitting (Dropout or Regularization)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQYTAigh1Xf"
      },
      "source": [
        "### What is Vanishing of Gradients ?\n",
        "- This problem basically occured in Deep Neural Networks(DNNs).\n",
        "- The activation function that caused such kind of issue is the \"Sigmoid AF\".\n",
        "- Gradients gets smaller and smaller as algorithm progress down to the lower layers.\n",
        "- So the lower layers are left untrained.\n",
        "- Training becomes very slow and no optimal value is reached.\n",
        "\n",
        " Ex - if $\\frac{\\partial e}{\\partial w_2}$ is the weight update and these are in ratios.\n",
        "\n",
        " $$\\frac{\\partial e}{\\partial w_2} = \\frac{\\partial e}{\\partial a_2} \\times \\frac{\\partial a_2}{\\partial z_2} \\times\\frac{\\partial z_2}{\\partial w_2}$$\n",
        "\n",
        "- If these values are very small then the resultant value would be a very small value ex. $0.0006$.\n",
        "\n",
        "- So there is almost no change in the weight.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBHD6-R4jdRp"
      },
      "source": [
        "### What is Exploding of Gradients ?\n",
        "- Its opposite of Vanishing Gradients.\n",
        "- Due to the large weights the gradients become heavier than the previous weights.\n",
        "- Resultant would be negative or very close to previous weights.\n",
        "- Many layers get insanely large weights updates. \n",
        "- It happens moatly in RNN's.\n",
        "\n",
        " Ex - Ratios become > 1. weight update like $6000$\n",
        "- In these cases the solution will diverge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICK-69_Hl6vb"
      },
      "source": [
        "### How do we handle Vanishing and Exploding gradient problem ?\n",
        "These are the two methods which are used to handle Vanishing and Exploding gradient problem.\n",
        "- Choise of Activation Function.\n",
        "- Weight Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9tgC_0_qBW1"
      },
      "source": [
        "### What are Activation Functions and use of it ?\n",
        "- Helps to determine the output of the NN.\n",
        "- Determines whether a neuron should get activated or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXSgkcopqfRp"
      },
      "source": [
        "### What was the issue with Sigmoid AF ?\n",
        " ![image](https://miro.medium.com/max/3268/1*a04iKNbchayCAJ7-0QlesA.png)\n",
        "\n",
        "- As we can observe in the diagram that this function just worked well with **smaller weight initialization** or weights that are **initialized closer to zero**.\n",
        "- For larger weights the garadient of Sigmoid AF is **zero** and it goes into the **saturation state**. \n",
        "- In saturation state the Vanishing Gradient issue occurs as there is no weight update due to small gradient.\n",
        "- Therefore, sigmoid AF had the disadvantage of the Vanishing Gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ie3nziesBXw"
      },
      "source": [
        "### What should be the choise of AF rather than Sigmoid ?\n",
        "- ReLU or Rectified Linear Unit is one of the most popular used AF that can be used in replacement of Sigmoid in the inner layers. \n",
        "![relu](https://miro.medium.com/max/754/1*3JUMOqugWKB2SDra6x6v0A.png)\n",
        "- As we can observe that it has no such kind of issue of saturation.\n",
        "- Hence it would produce output for larger value also.\n",
        "- But, it has some issue like **dying relu**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYgyobuUs4sN"
      },
      "source": [
        "### What are the techniques of weight initialization ?\n",
        "- We can observe that if the weights are initialized withing the **non-saturation** only then our network can prevent vansihing and exploding gradient. \n",
        "- This can be done using **Glorot weight initialization technique** which states that \n",
        "\n",
        " The signal need to flow properly in both directions: in the forward direction\n",
        "when making predictions, and in the reverse direction when backpropagating gradients.\n",
        "- For the signal to flow properly, we need the variance of the outputs of each layer to be equal to the variance of its inputs, and we also need the gradients to have equal variance before and after flowing through a layer in the reverse direction.\n",
        "- They introduced two terms $fan_in$ and $fan_out$ and $fan_in = fan_out$ \n",
        "- This will only happen if $\\sigma_in^2 = \\sigma_out^2$\n",
        "\n",
        " $fan_avg = fan_in + fan_out /2$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGIGKB3n1Pa"
      },
      "source": [
        "### Comparing different types of weight initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR8onOwLc_Z0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfHm6hWHo0dd"
      },
      "source": [
        "minist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train_full, y_train_full), (X_test, y_test) = minist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28y7DETYo6Ah"
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train =  y_train_full[:5000], y_train_full[5000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUgVmYEmxnw1"
      },
      "source": [
        "### Use of Early Stopping and Checkpoints\n",
        "\n",
        "These are all types of callback implemented during model fitting. \n",
        "\n",
        "Early Stopping - Its a techinique in which the training is stopped if there no improvement in the metric for certain epochs and it returns the best weights.\n",
        "\n",
        "Mod elCheckpoint - It saves checkpoints of your model at regular intervals during training, by default at the end of each epoch. This would help if there is any problem while training and the training discontinues so we can continue from the last saved checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DqmIOcKy66K"
      },
      "source": [
        "# Early Stopping\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCKSiGhEzFh7"
      },
      "source": [
        "# Model Checkpoint saving\n",
        "CKPT_path = \"model_ckpt_06_09.h5\"\n",
        "checkpointing_cb = tf.keras.callbacks.ModelCheckpoint(CKPT_path, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BpnALZ5yheu",
        "outputId": "f00e68dd-f429-4803-c2fd-be300f4a66c9"
      },
      "source": [
        "model_3 = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = [28,28], name = 'input_layer'),\n",
        "                                     tf.keras.layers.Dense(300,activation='relu',name= 'hidden_layer1'),\n",
        "                                     tf.keras.layers.Dense(200, activation = 'relu', name = 'hidden_layer2'),\n",
        "                                     tf.keras.layers.Dense(100, activation = 'relu', name = 'hidden_layer3'),\n",
        "                                     tf.keras.layers.Dense(10, activation='softmax', name = 'output_layer')])\n",
        "\n",
        "LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
        "OPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\n",
        "METRICS = [\"accuracy\"]\n",
        "\n",
        "model_3.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=METRICS)\n",
        "\n",
        "EPOCHS = 50\n",
        "VALIDATION_SET = (X_valid, y_valid)\n",
        "\n",
        "history = model_3.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=VALIDATION_SET,batch_size = 32,\n",
        "                    callbacks= [early_stopping_cb, checkpointing_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1719/1719 [==============================] - 5s 2ms/step - loss: 0.6164 - accuracy: 0.8334 - val_loss: 0.2908 - val_accuracy: 0.9162\n",
            "Epoch 2/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2641 - accuracy: 0.9239 - val_loss: 0.2131 - val_accuracy: 0.9404\n",
            "Epoch 3/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2060 - accuracy: 0.9400 - val_loss: 0.1755 - val_accuracy: 0.9526\n",
            "Epoch 4/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1700 - accuracy: 0.9513 - val_loss: 0.1539 - val_accuracy: 0.9572\n",
            "Epoch 5/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1434 - accuracy: 0.9577 - val_loss: 0.1298 - val_accuracy: 0.9642\n",
            "Epoch 6/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1237 - accuracy: 0.9639 - val_loss: 0.1137 - val_accuracy: 0.9664\n",
            "Epoch 7/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1081 - accuracy: 0.9686 - val_loss: 0.1043 - val_accuracy: 0.9688\n",
            "Epoch 8/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0950 - accuracy: 0.9721 - val_loss: 0.1026 - val_accuracy: 0.9692\n",
            "Epoch 9/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0841 - accuracy: 0.9757 - val_loss: 0.0973 - val_accuracy: 0.9724\n",
            "Epoch 10/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0754 - accuracy: 0.9780 - val_loss: 0.0901 - val_accuracy: 0.9746\n",
            "Epoch 11/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0676 - accuracy: 0.9808 - val_loss: 0.0809 - val_accuracy: 0.9766\n",
            "Epoch 12/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0607 - accuracy: 0.9827 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
            "Epoch 13/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0547 - accuracy: 0.9848 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
            "Epoch 14/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0497 - accuracy: 0.9860 - val_loss: 0.0722 - val_accuracy: 0.9810\n",
            "Epoch 15/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0445 - accuracy: 0.9878 - val_loss: 0.0682 - val_accuracy: 0.9806\n",
            "Epoch 16/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.0678 - val_accuracy: 0.9816\n",
            "Epoch 17/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: 0.0712 - val_accuracy: 0.9800\n",
            "Epoch 18/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0332 - accuracy: 0.9914 - val_loss: 0.0672 - val_accuracy: 0.9806\n",
            "Epoch 19/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 0.0691 - val_accuracy: 0.9788\n",
            "Epoch 20/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0273 - accuracy: 0.9934 - val_loss: 0.0668 - val_accuracy: 0.9822\n",
            "Epoch 21/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 0.0673 - val_accuracy: 0.9810\n",
            "Epoch 22/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 0.0635 - val_accuracy: 0.9830\n",
            "Epoch 23/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0681 - val_accuracy: 0.9818\n",
            "Epoch 24/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0653 - val_accuracy: 0.9824\n",
            "Epoch 25/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9822\n",
            "Epoch 26/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.0633 - val_accuracy: 0.9828\n",
            "Epoch 27/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.0650 - val_accuracy: 0.9836\n",
            "Epoch 28/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.0639 - val_accuracy: 0.9808\n",
            "Epoch 29/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.0633 - val_accuracy: 0.9824\n",
            "Epoch 30/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0634 - val_accuracy: 0.9838\n",
            "Epoch 31/50\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.0682 - val_accuracy: 0.9830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyBscXcr1Zvg"
      },
      "source": [
        "### Observation\n",
        "When implemented Early Stopping It interrupt training when it measures no progress on the validation set for a number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-liL7I4xg3X"
      },
      "source": [
        "### Comparing different types of weight initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Epq9nYpuDN"
      },
      "source": [
        "#### Glorot Initialization\n",
        "Glorot normal\n",
        "\n",
        "variance = $\\frac{1}{fan \\tiny avg}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LugsD19Yo6ZQ"
      },
      "source": [
        "model_1 = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = [28,28], name = 'input_layer'),\n",
        "                                     tf.keras.layers.Dense(300,activation='relu', kernel_initializer= 'glorot_normal'),\n",
        "                                     tf.keras.layers.Dense(200, activation = 'relu', kernel_initializer= 'glorot_normal'),\n",
        "                                     tf.keras.layers.Dense(100, activation = 'relu', kernel_initializer= 'glorot_normal'),\n",
        "                                     tf.keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGlRt7jCppDx",
        "outputId": "718aa70c-0e1d-4978-c107-5c32f2e9ebaf"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Flatten)        (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200)               60200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 316,810\n",
            "Trainable params: 316,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcx6YXcXprjA"
      },
      "source": [
        "LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
        "OPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\n",
        "METRICS = [\"accuracy\"]\n",
        "\n",
        "model_1.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=METRICS)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IInXN-AMqAVF",
        "outputId": "03646e6c-3816-457b-a1db-a79e5f807da5"
      },
      "source": [
        "EPOCHS = 10\n",
        "VALIDATION_SET = (X_valid, y_valid)\n",
        "\n",
        "history = model_1.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=VALIDATION_SET,batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 5s 2ms/step - loss: 0.5863 - accuracy: 0.8405 - val_loss: 0.2727 - val_accuracy: 0.9234\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2595 - accuracy: 0.9249 - val_loss: 0.2069 - val_accuracy: 0.9388\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2040 - accuracy: 0.9412 - val_loss: 0.1744 - val_accuracy: 0.9512\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1681 - accuracy: 0.9513 - val_loss: 0.1481 - val_accuracy: 0.9570\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1441 - accuracy: 0.9578 - val_loss: 0.1347 - val_accuracy: 0.9632\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1244 - accuracy: 0.9636 - val_loss: 0.1204 - val_accuracy: 0.9680\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9692 - val_loss: 0.1136 - val_accuracy: 0.9666\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0967 - accuracy: 0.9719 - val_loss: 0.1018 - val_accuracy: 0.9704\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9753 - val_loss: 0.0983 - val_accuracy: 0.9716\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0764 - accuracy: 0.9779 - val_loss: 0.0927 - val_accuracy: 0.9738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zk5LVVxqUco"
      },
      "source": [
        "Glorot Uniform\n",
        "\n",
        "Uniform ditribution between r and -r and r = $\\sqrt{\\frac{3}{fan\\tiny avg}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvrDOAWsqPYd"
      },
      "source": [
        "model_2 = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = [28,28], name = 'input_layer'),\n",
        "                                     tf.keras.layers.Dense(300,activation='relu', kernel_initializer= 'glorot_uniform'),\n",
        "                                     tf.keras.layers.Dense(200, activation = 'relu', kernel_initializer= 'glorot_uniform'),\n",
        "                                     tf.keras.layers.Dense(100, activation = 'relu', kernel_initializer= 'glorot_uniform'),\n",
        "                                     tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByyhwwDXqvAP",
        "outputId": "ddcd1d62-b33a-45f8-b240-04f250c4d649"
      },
      "source": [
        "LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
        "OPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\n",
        "METRICS = [\"accuracy\"]\n",
        "\n",
        "model_2.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=METRICS)\n",
        "\n",
        "EPOCHS = 10\n",
        "VALIDATION_SET = (X_valid, y_valid)\n",
        "\n",
        "history = model_2.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=VALIDATION_SET,batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6134 - accuracy: 0.8335 - val_loss: 0.2745 - val_accuracy: 0.9242\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2608 - accuracy: 0.9239 - val_loss: 0.2194 - val_accuracy: 0.9376\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2023 - accuracy: 0.9406 - val_loss: 0.1661 - val_accuracy: 0.9532\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1649 - accuracy: 0.9522 - val_loss: 0.1545 - val_accuracy: 0.9564\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1384 - accuracy: 0.9597 - val_loss: 0.1278 - val_accuracy: 0.9638\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1187 - accuracy: 0.9654 - val_loss: 0.1161 - val_accuracy: 0.9680\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1036 - accuracy: 0.9701 - val_loss: 0.1099 - val_accuracy: 0.9708\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0908 - accuracy: 0.9734 - val_loss: 0.0984 - val_accuracy: 0.9718\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9764 - val_loss: 0.1013 - val_accuracy: 0.9706\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0718 - accuracy: 0.9793 - val_loss: 0.0903 - val_accuracy: 0.9732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ9CQysUq3nM"
      },
      "source": [
        "#### Evaluating both\n",
        "**Observation** - Both perform in equal manner but may get affected for larger epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89B1V5lDq07c",
        "outputId": "acb7646a-e153-480e-d55e-afe030f0a7e3"
      },
      "source": [
        "print(\"For Glorot normal is {}\".format(model_1.evaluate(X_test, y_test)))\n",
        "print(\"For Glorot uniform is {}\".format(model_2.evaluate(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 14.6952 - accuracy: 0.9724\n",
            "For Glorot normal is [14.695219039916992, 0.9724000096321106]\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 14.8997 - accuracy: 0.9703\n",
            "For Glorot uniform is [14.899723052978516, 0.970300018787384]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8k4A80esR9b"
      },
      "source": [
        "### He initialization\n",
        "He normal\n",
        "\n",
        "variance = $\\frac{2}{fan \\tiny in}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89CWsx3Gr-b1"
      },
      "source": [
        "model_1 = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = [28,28], name = 'input_layer'),\n",
        "                                     tf.keras.layers.Dense(300,activation='relu', kernel_initializer= 'he_normal'),\n",
        "                                     tf.keras.layers.Dense(200, activation = 'relu', kernel_initializer= 'he_normal'),\n",
        "                                     tf.keras.layers.Dense(100, activation = 'relu', kernel_initializer= 'he_normal'),\n",
        "                                     tf.keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Np8-1N5sxAR",
        "outputId": "a086fc77-69ee-4037-f1ae-fdd3fe501b05"
      },
      "source": [
        "LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
        "OPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\n",
        "METRICS = [\"accuracy\"]\n",
        "\n",
        "model_1.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=METRICS)\n",
        "\n",
        "EPOCHS = 10\n",
        "VALIDATION_SET = (X_valid, y_valid)\n",
        "\n",
        "history = model_1.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=VALIDATION_SET,batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5101 - accuracy: 0.8599 - val_loss: 0.2565 - val_accuracy: 0.9276\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2353 - accuracy: 0.9317 - val_loss: 0.1899 - val_accuracy: 0.9488\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1811 - accuracy: 0.9475 - val_loss: 0.1554 - val_accuracy: 0.9568\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1473 - accuracy: 0.9568 - val_loss: 0.1479 - val_accuracy: 0.9604\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1241 - accuracy: 0.9634 - val_loss: 0.1211 - val_accuracy: 0.9672\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1069 - accuracy: 0.9687 - val_loss: 0.1108 - val_accuracy: 0.9686\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0936 - accuracy: 0.9725 - val_loss: 0.1019 - val_accuracy: 0.9708\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0822 - accuracy: 0.9765 - val_loss: 0.0992 - val_accuracy: 0.9740\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0730 - accuracy: 0.9790 - val_loss: 0.0969 - val_accuracy: 0.9718\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0653 - accuracy: 0.9814 - val_loss: 0.0926 - val_accuracy: 0.9744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teg8ytI8tKj3"
      },
      "source": [
        "He uniform with elu activation function sometimes performs better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6szU5xYs0Vp",
        "outputId": "50ca2118-2687-4d1f-ac6b-5a2f1d49a2d6"
      },
      "source": [
        "model_2 = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = [28,28], name = 'input_layer'),\n",
        "                                     tf.keras.layers.Dense(300,activation='elu', kernel_initializer= 'he_normal'),\n",
        "                                     tf.keras.layers.Dense(200, activation = 'elu', kernel_initializer= 'he_normal'),\n",
        "                                     tf.keras.layers.Dense(100, activation = 'elu', kernel_initializer= 'he_normal'),\n",
        "                                     tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
        "OPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\n",
        "METRICS = [\"accuracy\"]\n",
        "\n",
        "model_2.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=METRICS)\n",
        "\n",
        "EPOCHS = 10\n",
        "VALIDATION_SET = (X_valid, y_valid)\n",
        "\n",
        "history = model_2.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=VALIDATION_SET,batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4322 - accuracy: 0.8779 - val_loss: 0.2662 - val_accuracy: 0.9276\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2546 - accuracy: 0.9258 - val_loss: 0.2103 - val_accuracy: 0.9418\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2038 - accuracy: 0.9403 - val_loss: 0.1766 - val_accuracy: 0.9536\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1719 - accuracy: 0.9497 - val_loss: 0.1583 - val_accuracy: 0.9590\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1501 - accuracy: 0.9561 - val_loss: 0.1404 - val_accuracy: 0.9638\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1334 - accuracy: 0.9610 - val_loss: 0.1301 - val_accuracy: 0.9630\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1200 - accuracy: 0.9644 - val_loss: 0.1200 - val_accuracy: 0.9678\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1091 - accuracy: 0.9679 - val_loss: 0.1146 - val_accuracy: 0.9666\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1000 - accuracy: 0.9702 - val_loss: 0.1037 - val_accuracy: 0.9710\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0917 - accuracy: 0.9724 - val_loss: 0.0973 - val_accuracy: 0.9716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAUWyo8ctcEF"
      },
      "source": [
        "#### Evaluating Both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VblTXFAVtSfp",
        "outputId": "8cb1db21-f545-4957-ac26-b0eb8c35cb04"
      },
      "source": [
        "print(\"For he normal is {}\".format(model_1.evaluate(X_test, y_test)))\n",
        "print(\"For he normal with elu AF is {}\".format(model_2.evaluate(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 15.5938 - accuracy: 0.9713\n",
            "For he normal is [15.593754768371582, 0.9713000059127808]\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 41.6362 - accuracy: 0.8619\n",
            "For he normal with elu AF is [41.63624572753906, 0.8618999719619751]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBInmeFbufLP"
      },
      "source": [
        "#### Obsevation is He initialization performs better with ReLU and its variant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyiZFUHTveQ5"
      },
      "source": [
        "#### Lecun Initialization with SELU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoaNN_pctrcX",
        "outputId": "4b40cbf7-59b2-4d02-9db4-0e3cae580aae"
      },
      "source": [
        "model_1 = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = [28,28], name = 'input_layer'),\n",
        "                                     tf.keras.layers.Dense(300,activation='selu', kernel_initializer= 'LecunNormal'),\n",
        "                                     tf.keras.layers.Dense(200, activation = 'selu', kernel_initializer= 'LecunNormal'),\n",
        "                                     tf.keras.layers.Dense(100, activation = 'selu', kernel_initializer= 'LecunNormal'),\n",
        "                                     tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "LOSS_FUNCTION = \"sparse_categorical_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
        "OPTIMIZER = \"SGD\" # or use with custom learning rate=> tf.keras.optimizers.SGD(0.02)\n",
        "METRICS = [\"accuracy\"]\n",
        "\n",
        "model_1.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=METRICS)\n",
        "\n",
        "EPOCHS = 10\n",
        "VALIDATION_SET = (X_valid, y_valid)\n",
        "\n",
        "history = model_1.fit(X_train, y_train, epochs=EPOCHS,\n",
        "                    validation_data=VALIDATION_SET,batch_size = 32)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4004 - accuracy: 0.8855 - val_loss: 0.2712 - val_accuracy: 0.9210\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2650 - accuracy: 0.9225 - val_loss: 0.2323 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2257 - accuracy: 0.9351 - val_loss: 0.1996 - val_accuracy: 0.9434\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1942 - accuracy: 0.9441 - val_loss: 0.1753 - val_accuracy: 0.9512\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1692 - accuracy: 0.9510 - val_loss: 0.1574 - val_accuracy: 0.9548\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1489 - accuracy: 0.9570 - val_loss: 0.1444 - val_accuracy: 0.9590\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1333 - accuracy: 0.9608 - val_loss: 0.1346 - val_accuracy: 0.9606\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1198 - accuracy: 0.9646 - val_loss: 0.1208 - val_accuracy: 0.9656\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1078 - accuracy: 0.9683 - val_loss: 0.1148 - val_accuracy: 0.9654\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0987 - accuracy: 0.9717 - val_loss: 0.1084 - val_accuracy: 0.9682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY3bzcJ9wPKb"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSNm3E--ucJa",
        "outputId": "cb249603-f4be-4ad6-b417-9965987f6f52"
      },
      "source": [
        "print(\"For LeCun normal with elu AF is {}\".format(model_1.evaluate(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 28.0849 - accuracy: 0.7336\n",
            "For LeCun normal with elu AF is [28.084856033325195, 0.7336000204086304]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmv_DIaawfDC"
      },
      "source": [
        "#### Observation\n",
        "From above we can see that with this network Glorot Normal and He Normal gave the best result in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJxTrBRIwVaq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}